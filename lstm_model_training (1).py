# -*- coding: utf-8 -*-
"""lstm_model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vpw6XP0XJTjxtW--fdEPz8FnwS3wwwOP
"""

from google.colab import drive
drive.mount('/content/drive')
import os
# Force CPU-only so Keras emits standard LSTM ops
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# … then build and train your model as usual …

import numpy as np
import json
import joblib
import os

path = '/content/drive/MyDrive/can/preprocessed/'

X_train = np.load(path + 'X_train.npy')
X_val   = np.load(path + 'X_val.npy')
X_test  = np.load(path + 'X_test.npy')
y_train = np.load(path + 'y_train.npy')
y_val   = np.load(path + 'y_val.npy')
y_test  = np.load(path + 'y_test.npy')

# ✅ Load scaler using joblib only
scaler = joblib.load(os.path.join(path, 'scaler.pkl'))

# ✅ Load metadata
with open(os.path.join(path, 'metadata.json'), 'r') as f:
    metadata = json.load(f)

print(f"Train shape: {X_train.shape}, {y_train.shape}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

num_timesteps = X_train.shape[1]   # 20
num_features  = X_train.shape[2]   # 11
num_classes   = y_train.shape[1]   # 4

model = Sequential([
    LSTM(64, return_sequences=False, input_shape=(num_timesteps, num_features)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(num_classes, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    epochs=30,
    batch_size=64,
    validation_data=(X_val, y_val),
    callbacks=[early_stop]
)

loss, acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {acc*100:.2f}%")

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
import numpy as np
# Predict probabilities
y_pred_proba = model.predict(X_test)

# Convert probabilities to binary multilabel predictions
y_pred = (y_pred_proba > 0.5).astype(int)

# y_test and y_pred must be binarized multilabel outputs (shape: [n_samples, n_classes])
# class_names is the list of class labels in the correct order

class_names = ['Normal', 'DoS', 'Fuzzy', 'Impersonation']

for i, class_name in enumerate(class_names):
    cm = confusion_matrix(y_test[:, i], y_pred[:, i])

    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {class_name}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.xticks(ticks=[0.5, 1.5], labels=['No', 'Yes'])
    plt.yticks(ticks=[0.5, 1.5], labels=['No', 'Yes'])
    plt.tight_layout()
    plt.show()

from google.colab import drive
drive.mount('/content/drive')
import tensorflow as tf
model = tf.keras.models.load_model("/content/drive/MyDrive/can/lstm_model.keras")
tf.saved_model.save(model, "/content/drive/MyDrive/can/lstm_saved_model")

import tensorflow as tf

# Load the model
model = tf.keras.models.load_model("/content/drive/MyDrive/can/lstm_model.keras")

# 1. Print a summary of the model
model.summary()

import zipfile

keras_model_path = "/content/drive/MyDrive/can/lstm_model.keras"

with zipfile.ZipFile(keras_model_path, 'r') as zip_ref:
    zip_ref.printdir()

# ─── STEP 0: FORCE CPU ───────────────────────────────────────────────────────
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# ─── STEP 1: INSTALL DEPENDENCIES ────────────────────────────────────────────
!pip install tensorflow==2.12 tf2onnx onnxruntime seaborn matplotlib scikit-learn

# ─── STEP 2: IMPORTS & LOAD DATA ─────────────────────────────────────────────
import numpy as np
import joblib, json
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import tf2onnx
import onnxruntime as rt
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Mount Drive (if in Colab)
from google.colab import drive
drive.mount('/content/drive')

# Paths
base     = "/content/drive/MyDrive/can/"
pre      = base + "preprocessed/"
save_dir = base + "models/"
os.makedirs(save_dir, exist_ok=True)

# Load data
X_train = np.load(pre + "X_train.npy")
X_val   = np.load(pre + "X_val.npy")
X_test  = np.load(pre + "X_test.npy")
y_train = np.load(pre + "y_train.npy")
y_val   = np.load(pre + "y_val.npy")
y_test  = np.load(pre + "y_test.npy")

print("Shapes:", X_train.shape, y_train.shape, X_val.shape, y_val.shape)

# ─── STEP 3: BUILD & TRAIN MODEL ─────────────────────────────────────────────
num_timesteps = X_train.shape[1]
num_features  = X_train.shape[2]
num_classes   = y_train.shape[1]

model = Sequential([
    LSTM(64, return_sequences=False, input_shape=(num_timesteps, num_features)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(num_classes, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=64,
    callbacks=[es]
)

# ─── STEP 4: SAVE FORMATS ────────────────────────────────────────────────────
# SavedModel (.keras)
model.save(save_dir + "lstm_model_1.keras", save_format="keras")
# HDF5 (.h5)
model.save(save_dir + "lstm_model_1.h5")
# ONNX (.onnx)
spec = tf.TensorSpec((None, num_timesteps, num_features), tf.float32, name="input")
@tf.function(input_signature=[spec])
def infer(x): return model(x)
tf2onnx.convert.from_function(
    infer,
    opset=11,
    output_path=save_dir + "lstm_model_1.onnx"
)

# ─── STEP 5: CONFUSION MATRIX PLOTTING ───────────────────────────────────────
# Predict on test set
y_pred_proba = model.predict(X_test)
y_true = np.argmax(y_test, axis=1)
y_pred = np.argmax(y_pred_proba, axis=1)

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)
class_names = ['Normal','DoS','Fuzzy','Impersonation']

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix on Test Set")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

# ─── STEP 0: FORCE CPU ───────────────────────────────────────────────────────
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# ─── STEP 1: INSTALL DEPENDENCIES ────────────────────────────────────────────
!pip install tensorflow==2.12 tf2onnx onnxruntime seaborn matplotlib scikit-learn

# ─── STEP 2: IMPORTS & LOAD DATA ─────────────────────────────────────────────
import numpy as np
import joblib, json
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import tf2onnx
import onnxruntime as rt
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Mount Drive (if in Colab)
from google.colab import drive
drive.mount('/content/drive')

# Paths
base     = "/content/drive/MyDrive/can/"
pre      = base + "preprocessed/"
save_dir = base + "models/"
os.makedirs(save_dir, exist_ok=True)

# Load data
X_train = np.load(pre + "X_train.npy")
X_val   = np.load(pre + "X_val.npy")
X_test  = np.load(pre + "X_test.npy")
y_train = np.load(pre + "y_train.npy")
y_val   = np.load(pre + "y_val.npy")
y_test  = np.load(pre + "y_test.npy")

print("Shapes:", X_train.shape, y_train.shape, X_val.shape, y_val.shape)

# ─── STEP 3: BUILD & TRAIN MODEL ─────────────────────────────────────────────
num_timesteps = X_train.shape[1]
num_features  = X_train.shape[2]
num_classes   = y_train.shape[1]

model = Sequential([
    LSTM(64, return_sequences=False, input_shape=(num_timesteps, num_features)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(num_classes, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=64,
    callbacks=[es]
)

# ─── STEP 4: SAVE HDF5 FIRST (.h5) ───────────────────────────────────────────
h5_path = save_dir + "lstm_model_1.h5"
model.save(h5_path)
print(f"✅ HDF5 model saved to {h5_path}")

# ─── STEP 5: CONFUSION MATRIX PLOTTING ───────────────────────────────────────
# Predict on test set
y_pred_proba = model.predict(X_test)
y_true = np.argmax(y_test, axis=1)
y_pred = np.argmax(y_pred_proba, axis=1)

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)
class_names = ['Normal','DoS','Fuzzy','Impersonation']

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix on Test Set")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

# ─── STEP 6: SAVE OTHER FORMATS ───────────────────────────────────────────────
# SavedModel (.keras)
keras_path = save_dir + "lstm_model_1.keras"
model.save(keras_path, save_format="keras")
print(f"✅ SavedModel format to {keras_path}")

# ONNX (.onnx)
spec = tf.TensorSpec((None, num_timesteps, num_features), tf.float32, name="input")
@tf.function(input_signature=[spec])
def infer(x): return model(x)

onnx_path = save_dir + "lstm_model_1.onnx"
tf2onnx.convert.from_function(
    infer,
    input_signature=[spec],
    opset=11,
    output_path=onnx_path
)
print(f"✅ ONNX model saved to {onnx_path}")

# Optional ONNX runtime check
dummy = np.random.randn(1, num_timesteps, num_features).astype(np.float32)
sess = rt.InferenceSession(onnx_path)
inp, out = sess.get_inputs()[0].name, sess.get_outputs()[0].name
res = sess.run([out], {inp: dummy})
print("ONNX inference output shape:", res[0].shape)

from tensorflow.keras.models import load_model

# Load your existing .h5 model
h5_path = "/content/drive/MyDrive/can/models/lstm_model_1.h5"
model = load_model(h5_path)

# Re-save it in TensorFlow SavedModel format (for MATLAB/Simulink)
model.save("/content/drive/MyDrive/can/models/lstm_model_tf")
print("✅ Converted to SavedModel format")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
from tensorflow.keras.utils import plot_model

import tensorflow as tf

# Load the model
model = tf.keras.models.load_model("/content/drive/MyDrive/can/lstm_model.keras")


plot_model(model, to_file='lstm_architecture.png', show_shapes=True, show_layer_names=True)